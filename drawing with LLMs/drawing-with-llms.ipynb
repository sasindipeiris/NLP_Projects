{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"competition","sourceId":89659,"databundleVersionId":11735795},{"sourceType":"modelInstanceVersion","sourceId":104453,"databundleVersionId":9473239,"modelInstanceId":72256},{"sourceType":"kernelVersion","sourceId":224423433}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#| default_exp core\n# When exporting this notebook to a Python module (a .py file), put all the functions and classes from this notebook into a file called core.py.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:47:18.379422Z","iopub.execute_input":"2025-04-26T12:47:18.379615Z","iopub.status.idle":"2025-04-26T12:47:18.383810Z","shell.execute_reply.started":"2025-04-26T12:47:18.379599Z","shell.execute_reply":"2025-04-26T12:47:18.382951Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"nbdev is a tool developed by FastAI that lets you write, document, test, and build Python libraries directly inside Jupyter Notebooks.\nIt allows you to combine code, explanations, and examples in one place, and then automatically export the code into clean .py files to create real Python packages.\n\nWith nbdev, you use special notebook commands (like #| export and #| default_exp) to control which parts of your notebook become part of the library.\nIt also helps you generate documentation websites, manage version control, and write tests — all from notebooks.\n\nIn short, nbdev makes it possible to build professional Python projects while staying entirely inside Jupyter, blending coding, learning, and documenting into one powerful workflow.","metadata":{}},{"cell_type":"code","source":"# Mark this cell for export (used in some notebook-to-script tools)\n#| export\n\n# Import the concurrent module for parallel processing\nimport concurrent\n\n# Import io module for working with input/output streams (like files in memory)\nimport io\n\n# Import logging module to create logs for debugging or tracking\nimport logging\n\n# Import regular expressions module for pattern matching with text\nimport re\n\n# Import re2 (a faster and safer regex library optimized for performance)\nimport re2\n\n# Import cairosvg to convert SVG files into other formats like PNG or PDF\nimport cairosvg\n\n# Import kagglehub to easily download and import packages/models from Kaggle Hub\nimport kagglehub\n\n# Import torch for working with PyTorch (deep learning framework)\nimport torch\n\n# Import etree from lxml to parse and manipulate XML/SVG files\nfrom lxml import etree\n\n# Import Hugging Face transformers' modules for loading LLM models and tokenizers\n# Import AutoTokenizer: Automatically downloads and loads the correct tokenizer for a given LLM model\n# Import AutoModelForCausalLM: Loads a pre-trained Language Model designed for text generation (causal language modeling)\n# Import BitsAndBytesConfig: Allows setting configurations for loading models with lower precision (e.g., 8-bit, 4-bit) to save memory and speed up inference\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n\n# Download and import the svg-constraints package from Kaggle Hub (contains rules for validating SVGs)\nsvg_constraints = kagglehub.package_import('metric/svg-constraints')\n\n# Set the computation device to GPU if available, otherwise fallback to CPU\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:49:27.144025Z","iopub.execute_input":"2025-04-26T12:49:27.144336Z","iopub.status.idle":"2025-04-26T12:49:27.361447Z","shell.execute_reply.started":"2025-04-26T12:49:27.144318Z","shell.execute_reply":"2025-04-26T12:49:27.360902Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Define a Model class to load and prepare the LLM\nclass Model:\n    def __init__(self):\n        # Set up Quantization Configuration to load the model efficiently\n        quantization_config = BitsAndBytesConfig(\n            load_in_4bit=True,  # Load model weights using 4 bits instead of full precision\n            bnb_4bit_quant_type=\"nf4\",  # Use Normalized Float 4 (nf4) quantization for better accuracy\n            bnb_4bit_use_double_quant=True,  # Apply double quantization to save even more memory\n            bnb_4bit_compute_dtype=torch.float16,  # Perform computations in 16-bit floats for faster operations\n        )\n\n        # Download the pre-trained Gemma-2 9B model from Kaggle Hub\n        self.model_path = kagglehub.model_download('google/gemma-2/Transformers/gemma-2-9b-it/2')\n\n        # Load the tokenizer associated with the downloaded model\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_path)\n\n        # Load the actual pre-trained model for Causal Language Modeling (text generation)\n        self.model = AutoModelForCausalLM.from_pretrained(\n            self.model_path,\n            device_map=\"auto\",  # Automatically assign model to GPU if available, else CPU\n            quantization_config=quantization_config,  # Use the defined quantization settings while loading\n        )\n        self.prompt_template = \"\"\"Generate SVG code to visually represent the following text description, while respecting the given constraints.\n<constraints>\n* **Allowed Elements:** `svg`, `path`, `circle`, `rect`, `ellipse`, `line`, `polyline`, `polygon`, `g`, `linearGradient`, `radialGradient`, `stop`, `defs`\n* **Allowed Attributes:** `viewBox`, `width`, `height`, `fill`, `stroke`, `stroke-width`, `d`, `cx`, `cy`, `r`, `x`, `y`, `rx`, `ry`, `x1`, `y1`, `x2`, `y2`, `points`, `transform`, `opacity`\n</constraints>\n\n<example>\n<description>\"A red circle with a blue square inside\"</description>\n```svg\n<svg viewBox=\"0 0 256 256\" width=\"256\" height=\"256\">\n  <circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\"/>\n  <rect x=\"30\" y=\"30\" width=\"40\" height=\"40\" fill=\"blue\"/>\n</svg>\n```\n\n</example>\n\nPlease ensure that the generated SVG code is well-formed, valid, and strictly adheres to these constraints. Focus on a clear and concise representation of the input description within the given limitations. Always give the complete SVG code with nothing omitted. Never use an ellipsis.\n\n<description>\"{}\"</description>\n```svg\n<svg viewBox=\"0 0 256 256\" width=\"256\" height=\"256\">\n\"\"\"\n        self.default_svg = \"\"\"<svg width=\"256\" height=\"256\" viewBox=\"0 0 256 256\"><circle cx=\"50\" cy=\"50\" r=\"40\" fill=\"red\" /></svg>\"\"\"\n        self.constraints = svg_constraints.SVGConstraints()\n        self.timeout_seconds = 90\n\n   \n # Define a prediction function that generates an SVG from a text description\n# You can optionally set how many tokens (words/parts) the model can generate\n    def predict(self, description: str, max_new_tokens=512) -> str:\n    \n        # Inner function to actually generate the SVG\n        def generate_svg():\n            try:\n                # Format the input prompt by inserting the description into a predefined template\n                prompt = self.prompt_template.format(description)\n                \n                # Tokenize the prompt (convert text into model-readable format) and move to device (CPU/GPU)\n                inputs = self.tokenizer(text=prompt, return_tensors=\"pt\").to(DEVICE)\n    \n                # Turn off gradient tracking to speed up generation (no training happening)\n                with torch.no_grad():\n                    # Generate the output from the model\n                    output = self.model.generate(\n                        **inputs,\n                        max_new_tokens=max_new_tokens,  # Limit the number of new tokens generated\n                        do_sample=True,  # Randomize output for more creativity\n                    )\n    \n                # Decode the generated output tokens back into readable text\n                output_decoded = self.tokenizer.decode(output[0], skip_special_tokens=True)\n                logging.debug('Output decoded from model: %s', output_decoded)\n    \n                # Use regex to find anything between <svg>...</svg> tags\n                matches = re.findall(r\"<svg.*?</svg>\", output_decoded, re.DOTALL | re.IGNORECASE)\n                if matches:\n                    svg = matches[-1]  # Pick the last SVG found\n                else:\n                    return self.default_svg  # If no SVG found, return the default SVG\n    \n                logging.debug('Unprocessed SVG: %s', svg)\n    \n                # Apply SVG constraints (make sure the SVG is valid and safe)\n                svg = self.enforce_constraints(svg)\n                logging.debug('Processed SVG: %s', svg)\n    \n                # Test if the generated SVG can be successfully converted into PNG\n                cairosvg.svg2png(bytestring=svg.encode('utf-8'))\n    \n                return svg  # Return the valid generated SVG\n    \n            except Exception as e:\n                # If any error occurs, log it and return the default SVG\n                logging.error('Exception during SVG generation: %s', e)\n                return self.default_svg\n\n    def enforce_constraints(self, svg_string: str) -> str:\n            \"\"\"Enforces constraints on an SVG string, removing disallowed elements\n            and attributes.\n    \n            Parameters\n            ----------\n            svg_string : str\n                The SVG string to process.\n    \n            Returns\n            -------\n            str\n                The processed SVG string, or the default SVG if constraints\n                cannot be satisfied.\n            \"\"\"\n            logging.info('Sanitizing SVG...') \n            try:\n            # Create an XMLParser that removes blank text and comments from the SVG string\n               parser = etree.XMLParser(remove_blank_text=True, remove_comments=True)\n            \n            # Parse the SVG string into an XML element tree (structure)\n               root = etree.fromstring(svg_string, parser=parser)\n        \n            except etree.ParseError as e:\n                # If there is a parsing error (e.g., invalid SVG), log the error and return the default SVG\n               logging.error('SVG Parse Error: %s. Returning default SVG.', e)\n                \n                # Return the default SVG if the parsing fails\n               return self.default_svg\n            elements_to_remove = []\n            for element in root.iter():\n                tag_name = etree.QName(element.tag).localname\n        \n                # Remove disallowed elements\n                if tag_name not in self.constraints.allowed_elements:\n                    elements_to_remove.append(element)\n                    continue  # Skip attribute checks for removed elements  \n                # Remove disallowed attributes\n                attrs_to_remove = []\n                for attr in element.attrib:\n                    attr_name = etree.QName(attr).localname\n                    if (\n                        attr_name\n                        not in self.constraints.allowed_elements[tag_name]\n                        and attr_name\n                        not in self.constraints.allowed_elements['common']\n                    ):\n                        attrs_to_remove.append(attr)\n        \n                for attr in attrs_to_remove:\n                    logging.debug(\n                        'Attribute \"%s\" for element \"%s\" not allowed. Removing.',\n                        attr,\n                        tag_name,\n                    )\n                    del element.attrib[attr]\n                # Check and remove invalid href attributes\n                for attr, value in element.attrib.items():\n                     if etree.QName(attr).localname == 'href' and not value.startswith('#'):\n                        logging.debug(\n                            'Removing invalid href attribute in element \"%s\".', tag_name\n                        )\n                        del element.attrib[attr]\n                 # Validate path elements to help ensure SVG conversion\n                if tag_name == 'path':\n                    d_attribute = element.get('d')\n                    if not d_attribute:\n                        logging.warning('Path element is missing \"d\" attribute. Removing path.')\n                        elements_to_remove.append(element)\n                        continue # Skip further checks for this removed element\n\n\n                    # Use regex to validate 'd' attribute format\n                    path_regex = re2.compile(\n                        r'^'  # Start of string\n                        r'(?:'  # Non-capturing group for each command + numbers block\n                        r'[MmZzLlHhVvCcSsQqTtAa]'  # Valid SVG path commands (adjusted to exclude extra letters)\n                        r'\\s*'  # Optional whitespace after command\n                        r'(?:'  # Non-capturing group for optional numbers\n                        r'-?\\d+(?:\\.\\d+)?(?:[Ee][+-]?\\d+)?'  # First number\n                        r'(?:[\\s,]+-?\\d+(?:\\.\\d+)?(?:[Ee][+-]?\\d+)?)*'  # Subsequent numbers with mandatory separator(s)\n                        r')?'  # Numbers are optional (e.g. for Z command)\n                        r'\\s*'  # Optional whitespace after numbers/command block\n                        r')+'  # One or more command blocks\n                        r'\\s*'  # Optional trailing whitespace\n                        r'$'  # End of string\n                    )\n                if not path_regex.match(d_attribute):\n                    logging.warning(\n                        'Path element has malformed \"d\" attribute format. Removing path.'\n                    )\n                    elements_to_remove.append(element)\n                    continue\n                logging.debug('Path element \"d\" attribute validated (regex check).')\n                \n        \n            # Remove elements marked for removal\n            for element in elements_to_remove:\n                if element.getparent() is not None:\n                    element.getparent().remove(element)\n                    logging.debug('Removed element: %s', element.tag)\n    \n            try:\n                cleaned_svg_string = etree.tostring(root, encoding='unicode')\n                return cleaned_svg_string\n            except ValueError as e:\n                logging.error(\n                    'SVG could not be sanitized to meet constraints: %s', e\n                )\n                return self.default_svg\n            \n          ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:50:01.984039Z","iopub.execute_input":"2025-04-26T12:50:01.984309Z","iopub.status.idle":"2025-04-26T12:50:01.999963Z","shell.execute_reply.started":"2025-04-26T12:50:01.984288Z","shell.execute_reply":"2025-04-26T12:50:01.999194Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"The Model class is part of a machine learning pipeline designed to generate and process SVG (Scalable Vector Graphics) files based on textual descriptions. In the initialization method, the class sets up a quantization configuration to optimize the model's memory usage and computational efficiency. The model and tokenizer are loaded from a pre-trained model path, allowing it to process input text into a format that the model can understand. The `predict` method generates an SVG based on the input description by first formatting the description into a prompt, tokenizing it, and passing it through the model to generate a response. The model’s output is decoded, and an SVG is extracted using regular expressions. The generated SVG is then passed through a constraint enforcement function, which ensures that the SVG adheres to predefined constraints such as allowed tags and attributes. If the SVG passes validation, it can be converted to an image; if not, a default SVG is returned. The `enforce_constraints` method sanitizes the generated SVG by removing disallowed elements, attributes, and ensuring that path data is correctly formatted. This class effectively combines machine learning and data sanitization to generate valid, safe SVG images based on textual input, with error handling and logging to ensure the process runs smoothly.","metadata":{}},{"cell_type":"code","source":"# Import the kaggle_evaluation module to run evaluation tests on the model\nimport kaggle_evaluation\n\n# Set up logging to show INFO level messages (force=True ensures that this config will override any previous settings)\nlogging.basicConfig(level=logging.INFO, force=True)\n\n# Run the evaluation test on the Model class defined earlier\nkaggle_evaluation.test(Model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:50:14.374553Z","iopub.execute_input":"2025-04-26T12:50:14.374821Z","iopub.status.idle":"2025-04-26T12:52:14.534824Z","shell.execute_reply.started":"2025-04-26T12:50:14.374801Z","shell.execute_reply":"2025-04-26T12:52:14.533929Z"}},"outputs":[{"name":"stdout","text":"Creating Model instance...\n","output_type":"stream"},{"name":"stderr","text":"2025-04-26 12:50:23.202364: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1745671823.425378      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1745671823.490373      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"056ebaf447a14522947bbf0a20b7a4e7"}},"metadata":{}},{"name":"stdout","text":"Running inference tests...\nWrote test submission file to \"/tmp/kaggle-evaluation-submission-068o07w6.csv\".\nSuccess!\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def generate():\n    import polars as pl  # Import Polars, a fast DataFrame library (alternative to pandas) for efficient data manipulation\n    from IPython.display import SVG # Import SVG from IPython.display to render SVG images directly inside Jupyter notebooks or similar environments\n    import time  # Import the time module\n    \n    logging.basicConfig(level=logging.DEBUG, force=True)\n    \n    train = pl.read_csv('/kaggle/input/drawing-with-llms/train.csv')\n    display(train.head())\n    \n    model = Model()\n    svgs = []\n    for desc in train.get_column('description'):\n        start_time = time.time()  # Record start time\n        svg = model.predict(desc)\n        end_time = time.time()    # Record end time\n        elapsed_time = end_time - start_time # Calculate elapsed time\n        print(f\"Prediction time for description '{desc[:20]}...': {elapsed_time:.4f} seconds\") # Print time\n    \n        try:\n            display(SVG(svg))\n           \n        except Exception as e:\n            print(e)\n            continue\n\ngenerate()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-26T12:59:52.380245Z","iopub.execute_input":"2025-04-26T12:59:52.380884Z","iopub.status.idle":"2025-04-26T13:00:13.653919Z","shell.execute_reply.started":"2025-04-26T12:59:52.380861Z","shell.execute_reply":"2025-04-26T13:00:13.653291Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"shape: (5, 2)\n┌────────┬─────────────────────────────────┐\n│ id     ┆ description                     │\n│ ---    ┆ ---                             │\n│ str    ┆ str                             │\n╞════════╪═════════════════════════════════╡\n│ 02d892 ┆ a purple forest at dusk         │\n│ 0dcd2e ┆ gray wool coat with a faux fur… │\n│ 1e9ac1 ┆ a lighthouse overlooking the o… │\n│ 2b25db ┆ burgundy corduroy pants with p… │\n│ 4e6a54 ┆ orange corduroy overalls        │\n└────────┴─────────────────────────────────┘","text/html":"<div><style>\n.dataframe > thead > tr,\n.dataframe > tbody > tr {\n  text-align: right;\n  white-space: pre-wrap;\n}\n</style>\n<small>shape: (5, 2)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>description</th></tr><tr><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;02d892&quot;</td><td>&quot;a purple forest at dusk&quot;</td></tr><tr><td>&quot;0dcd2e&quot;</td><td>&quot;gray wool coat with a faux fur…</td></tr><tr><td>&quot;1e9ac1&quot;</td><td>&quot;a lighthouse overlooking the o…</td></tr><tr><td>&quot;2b25db&quot;</td><td>&quot;burgundy corduroy pants with p…</td></tr><tr><td>&quot;4e6a54&quot;</td><td>&quot;orange corduroy overalls&quot;</td></tr></tbody></table></div>"},"metadata":{}},{"name":"stderr","text":"DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): dp.kaggle.net:443\nDEBUG:urllib3.connectionpool:https://dp.kaggle.net:443 \"POST /kaggle-jwt-handler/AttachDatasourceUsingJwtRequest HTTP/1.1\" 200 None\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9957c93adc5d468eb116390546293cce"}},"metadata":{}},{"name":"stdout","text":"Prediction time for description 'a purple forest at d...': 0.0000 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>"},"metadata":{}},{"name":"stdout","text":"None\nPrediction time for description 'gray wool coat with ...': 0.0000 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>"},"metadata":{}},{"name":"stdout","text":"None\nPrediction time for description 'a lighthouse overloo...': 0.0000 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>"},"metadata":{}},{"name":"stdout","text":"None\nPrediction time for description 'burgundy corduroy pa...': 0.0000 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>"},"metadata":{}},{"name":"stdout","text":"None\nPrediction time for description 'orange corduroy over...': 0.0000 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>"},"metadata":{}},{"name":"stdout","text":"None\nPrediction time for description 'a purple silk scarf ...': 0.0000 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>"},"metadata":{}},{"name":"stdout","text":"None\nPrediction time for description 'a green lagoon under...': 0.0000 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>"},"metadata":{}},{"name":"stdout","text":"None\nPrediction time for description 'crimson rectangles f...': 0.0000 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>"},"metadata":{}},{"name":"stdout","text":"None\nPrediction time for description 'purple pyramids spir...': 0.0000 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>"},"metadata":{}},{"name":"stdout","text":"None\nPrediction time for description 'magenta trapezoids l...': 0.0000 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>"},"metadata":{}},{"name":"stdout","text":"None\nPrediction time for description 'a snowy plain...': 0.0000 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>"},"metadata":{}},{"name":"stdout","text":"None\nPrediction time for description 'black and white chec...': 0.0000 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>"},"metadata":{}},{"name":"stdout","text":"None\nPrediction time for description 'a starlit night over...': 0.0000 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>"},"metadata":{}},{"name":"stdout","text":"None\nPrediction time for description 'khaki triangles and ...': 0.0000 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>"},"metadata":{}},{"name":"stdout","text":"None\nPrediction time for description 'a maroon dodecahedro...': 0.0000 seconds\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.SVG object>"},"metadata":{}},{"name":"stdout","text":"None\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"Summary\n\nFirst, I imported several important libraries needed for model loading, SVG handling, and optimization, including torch, transformers, kagglehub, cairosvg, lxml.etree, and re2. I set up the device (CPU or GPU) for running the model using torch.device. I then initialized a Model class. Inside the Model, I configured 4-bit quantization using BitsAndBytesConfig to make the model run lighter and faster. I downloaded a pre-trained model from KaggleHub (specifically, Google's Gemma-2 model) and loaded it with AutoTokenizer and AutoModelForCausalLM.\n\nI also prepared a default SVG string (a simple red circle) to return in case anything went wrong. I defined SVG constraints to make sure any generated SVG follows safe, clean rules — only allowing certain tags and attributes, and validating structure carefully. I set a timeout value of 90 seconds for SVG generation to prevent long-running processes.\n\nIn the predict method, I designed the logic to take a text description, create a prompt, generate output from the model, extract SVG code using regex, apply constraints, and finally validate it by trying to convert it with cairosvg. If any step failed, I returned the default SVG. I used logging to track and debug important steps.\n\nTo enforce constraints, I parsed the generated SVG string using lxml.etree.XMLParser, removed disallowed elements (like <script>) and disallowed attributes (like onclick), validated important attributes such as the \"d\" attribute of <path> elements using regex, and finally re-assembled the cleaned SVG. If any problem occurred while cleaning, I safely fell back to the default SVG.\n\nFinally, I wrote test code to evaluate the model using Kaggle's kaggle_evaluation module. Before doing that, I also imported polars for possible data handling and IPython.display.SVG to visually display the SVGs inside notebooks.\n\nIn short, I built a system that takes a text description, uses a large language model to generate an SVG image, strictly cleans and validates the SVG based on set constraints, and outputs a safe, valid SVG image.\n","metadata":{}}]}