# Overview

This project is a submission for the Kaggle competition that challenges participants to build LLM-powered systems that generate SVG code from natural language prompts. The model aims to translate textual descriptions into scalable, well-formed vector graphics (SVG) that adhere to strict rendering and validation constraints.

# SVG

Scalable Vector Graphics (SVG) is an XML-based markup language for describing two-dimensional vector graphics. Unlike raster images (e.g., PNG or JPEG), which are made of pixels, SVG images are defined using geometric primitives such as lines, circles, rectangles, and paths. This allows SVGs to be scaled infinitely without any loss in quality, making them ideal for modern web and interface design.

**Key Features of SVG**

1.Resolution-independent: Can be zoomed and resized without distortion.

2.Editable: SVG files are plain text, meaning they can be edited in any text editor or generated dynamically with code.

3.Scriptable and Styleable: Supports interactivity and animations via JavaScript and CSS.

4.Web-native: Natively supported in all modern browsers without needing plugins.

5.Semantic: Can be parsed, validated, and transformed easily like other XML-based data formats.

In the context of this project, SVG is used as the target output format generated by a large language model in response to text descriptions. The ability to reason about shapes, colors, sizes, and layout—then translate that reasoning into executable SVG code—is what sets this challenge apart.


# Libraries used


| Library               | Purpose |
|------------------------|---------|
| `bitsandbytes`         | Loads the Gemma model in 4-bit precision to reduce memory usage. |
| `cairosvg`             | Converts SVG strings into PNGs for visual rendering and validation. |
| `lxml.etree`           | Parses and sanitizes SVG XML; removes disallowed tags and attributes. |
| `re2`                  | Validates the `d` attribute of SVG `path` elements using regex. |
| `re`                   | Handles general regular expressions and parsing logic. |
| `concurrent.futures`   | Runs the SVG generation in a separate thread with timeout control. |
| `io`                   | Handles in-memory file streams for SVG conversion and manipulation. |
| `logging`              | Outputs logs and error messages for debugging and execution tracing. |
| `torch`                | Backend framework for loading and running the quantized Gemma model. |
| `transformers`         | Loads the `Gemma-2-9B-IT` model and tokenizer via Hugging Face. |
| `kagglehub`            | Downloads packages and models directly from Kaggle Hub. |
| `AutoTokenizer`        | Tokenizes the input prompt before LLM inference. |
| `AutoModelForCausalLM` | Loads a causal language model (Gemma) for text-to-SVG generation. |
| `BitsAndBytesConfig`   | Configures quantized model loading to run efficiently in low memory environments. |

# Model class

The Model class is the core of this notebook and serves as the interface for generating SVG code from natural language prompts. It encapsulates everything required to take a text description (such as “A green circle inside a red square”) and return a corresponding SVG string that visually represents it. The class not only performs text generation using a powerful language model but also includes careful handling of constraints, structure validation, and error control. This modular, production-ready design is tailored for Kaggle’s image generation competition using the Gemma 2 9B IT model.

**Initialization**

Upon instantiation, the class performs several setup tasks essential for the prediction process:

**1.Model Loading**

The Gemma 2 9B IT model is downloaded via kagglehub and loaded using Hugging Face’s transformers library. The AutoTokenizer is used to tokenize the input prompt (i.e., convert it into model-understandable tokens), while AutoModelForCausalLM is used to load the actual language model trained for causal (left-to-right) text generation.

**2.Quantization with BitsAndBytes**

The model is loaded with 4-bit quantization using BitsAndBytesConfig. This drastically reduces memory consumption without severely impacting output quality. Options like bnb_4bit_quant_type="nf4" and using float16 precision are set for computational efficiency. This allows the large model to run on typical Kaggle GPUs or local machines with limited resources.

**3.Prompt Template Definition**

A structured prompt template is stored as a string in self.prompt_template. This template contains:

A task instruction: asks the model to generate SVG code from a textual description.

A section defining allowed SVG elements and attributes.

An example prompt and SVG output to guide the model through few-shot learning.

**4.SVG Constraints and Defaults**

The svg_constraints package is imported from Kaggle Hub to validate output. A fallback default SVG is stored in self.default_svg (a simple circle) to be returned in case of errors or timeouts. The timeout for predictions is also set (self.timeout_seconds = 90), ensuring the process does not hang indefinitely.

**Prediction Method**

The predict function is the core method that accepts a natural language prompt and returns an SVG image in string format.

**1.Prompt Construction**

The input description is formatted into the previously defined prompt_template, producing a full prompt that includes task instructions, constraints, examples, and the user query.

**2.Tokenization and inference**

The formatted prompt is tokenized using the tokenizer, then passed to the model for generation using model.generate(...). The generation is done with:

do_sample=True for creative, non-deterministic output.

max_new_tokens to limit the output length.

**3.SVG Extraction via Regex**

After decoding the generated tokens, the code searches the output for a full <svg>...</svg> block using regular expressions. If found, that segment is retained. If not, the method falls back to returning the default SVG.

**4.SVG Constraint Enforcement**

The extracted SVG code is passed to enforce_constraints(...) to ensure only allowed elements and attributes are retained. This step is crucial to meet Kaggle’s validation and scoring rules.

**5.Validate via rendering**

The cairosvg library attempts to render the SVG to PNG in memory. If rendering fails, the output is assumed invalid, and the fallback SVG is returned.

**6.Timeout Handling**

The entire SVG generation logic is executed inside a thread pool using concurrent.futures.ThreadPoolExecutor. This ensures that if the model takes too long to respond (e.g., due to excessive token generation or an internal error), the system will timeout after 90 seconds and return a valid fallback SVG.

**Constraint Enforcement**

This function cleans and validates the generated SVG to ensure it complies with Kaggle’s strict evaluation rules.

**1.XML Parsing**

XML parsing with lxml.etree converts the raw SVG string into a structured format. If the SVG is malformed and cannot be parsed, the code falls back to a default safe SVG. This ensures your model is robust, predictable, and compliant with expected standards.

**2.Disallowed Elements $ Attributes**

The parsed tree is traversed to check whether each element and its attributes are allowed based on the imported svg_constraints rules:

Any element not on the allowed list is removed.

Attributes not explicitly allowed for a given element (or not globally allowed) are also stripped.

**3.Path attribute validation**

For <path> elements, the d attribute (which defines vector shapes) is validated using a strict regex powered by re2. Paths with malformed or missing d values are removed to prevent rendering errors.

**4.Safe output generation**

Once cleaned, the SVG tree is converted back into a string. If this fails for any reason (e.g., encoding issues), the fallback SVG is returned.

# Evaluation

This section of the code performs the official evaluation of the Model class using Kaggle’s provided testing framework. It begins by importing the kaggle_evaluation module, which contains standardized tools to validate and score submissions according to the competition's rules.

Next, the logging system is configured using logging.basicConfig(...) to display all messages at the INFO level or higher. The force=True argument ensures this configuration is applied even if logging was previously set up elsewhere in the notebook or environment.

Finally, the line kaggle_evaluation.test(Model) executes the evaluation routine. This function automatically instantiates the Model class and runs a predefined set of test prompts through its predict() method. The outputs are then validated for correctness, compliance with SVG constraints, and visual alignment with the prompt. This step mimics the conditions under which the model will be judged in the competition and provides immediate feedback on whether the model meets the expected behavior and format standards.

# Generate Class

The `generate()` function is a utility designed to visually test and inspect how well the `Model` class performs on real data from the training set. It begins by importing necessary libraries, including `polars` for fast CSV file reading, `IPython.display.SVG` for rendering SVGs inline, and `time` to measure how long each prediction takes. Logging is configured at the debug level to capture detailed output during execution.

The function then reads the training dataset (`train.csv`) using Polars and displays its top few rows for verification. An instance of the `Model` class is created, and the function iterates through each image description in the dataset. For each description, it records the start and end times around the `predict()` call to measure how long the model takes to generate an SVG. This duration is printed alongside a preview of the input text.

After generation, the SVG output is displayed using `IPython.display.SVG`, allowing for immediate visual confirmation of the result. If any rendering or prediction error occurs, it is caught and printed, and the loop continues to the next entry. This function serves as a practical testbed to evaluate both the **performance (speed)** and **quality (visual correctness)** of the model’s predictions. It is especially useful for debugging or iterating on model improvements.

# Summary

This notebook presents a complete solution for the Kaggle “Drawing with LLMs” competition, where the objective is to convert natural language prompts into valid, semantically accurate SVG (Scalable Vector Graphics) code using a quantized large language model. The solution uses Google’s Gemma 2 9B IT model, accessed via Hugging Face Transformers and loaded in 4-bit format using BitsAndBytes to reduce memory usage. The core functionality is wrapped in a `Model` class that defines a `predict()` method which formats the input prompt, performs inference, extracts and validates the SVG, and ensures compliance with strict element and attribute constraints using `lxml.etree` and regex-based rules (`re2`). Renderability is verified using `cairosvg`, and the entire generation process is executed within a time-limited thread to prevent hangs. The `kaggle_evaluation` tool tests the model's compatibility with competition standards, while a custom `generate()` function reads samples from the dataset, predicts and visualizes SVGs using `polars` and `IPython.display.SVG`. The system includes robust logging, error handling, and a fallback mechanism to ensure a valid output is always returned, making it a practical and production-ready approach for controlled code generation from text.







